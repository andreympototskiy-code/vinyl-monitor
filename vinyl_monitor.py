import json
import os
import re
import time
from html import escape
from pathlib import Path
from typing import Dict, List, Set

import requests
from dotenv import load_dotenv

load_dotenv()

USE_PLAYWRIGHT = os.getenv("USE_PLAYWRIGHT", "true").lower() == "true"
if USE_PLAYWRIGHT:
    from playwright.sync_api import sync_playwright

CATALOG_URL = os.getenv("CATALOG_URL", "https://korobkavinyla.ru/catalog")
KOROBKA_SALE_URL = os.getenv("KOROBKA_SALE_URL", "https://korobkavinyla.ru/catalog?tfc_sort%5B771567999%5D=created:desc&tfc_quantity%5B771567999%5D=y&tfc_storepartuid%5B771567999%5D=Sale&tfc_div=:::")
VINYLTAP_URLS = os.getenv("VINYLTAP_URLS", "https://vinyltap.co.uk/collections/new-releases,https://vinyltap.co.uk/collections/upcoming-releases").split(",")
PLASTINKA_URL = os.getenv("PLASTINKA_URL", "https://plastinka.com/lp")
STATE_PATH = Path(os.getenv("STATE_PATH", "./state.json")).expanduser().resolve()
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "")
REQUEST_TIMEOUT_SEC = 120
LOAD_MORE_MAX_CLICKS = 20
LOAD_MORE_WAIT_MS = 1200

# –ò–Ω—Ç–µ—Ä–≤–∞–ª—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤ —á–∞—Å–∞—Ö
KOROBKA_MONITOR_INTERVAL_HOURS = int(os.getenv("KOROBKA_MONITOR_INTERVAL_HOURS", "3"))  # 3 —á–∞—Å–∞ –¥–ª—è korobkavinyla.ru
VINYLTAP_MONITOR_INTERVAL_HOURS = int(os.getenv("VINYLTAP_MONITOR_INTERVAL_HOURS", "3"))  # 3 —á–∞—Å–∞ –¥–ª—è vinyltap.co.uk
AVITO_MONITOR_INTERVAL_HOURS = int(os.getenv("AVITO_MONITOR_INTERVAL_HOURS", "6"))  # 6 —á–∞—Å–æ–≤ –¥–ª—è –ê–≤–∏—Ç–æ
PLASTINKA_MONITOR_INTERVAL_HOURS = int(os.getenv("PLASTINKA_MONITOR_INTERVAL_HOURS", "6"))  # 6 —á–∞—Å–æ–≤ –¥–ª—è plastinka.com


def load_state() -> Set[str]:
    if STATE_PATH.exists():
        try:
            with open(STATE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ (–º–∞—Å—Å–∏–≤ ID) –∏ –Ω–æ–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ (–æ–±—ä–µ–∫—Ç —Å timestamp)
            if "known_ids" in data and isinstance(data["known_ids"], list):
                # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç - –º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫
                return set(data["known_ids"])
            elif "known_items" in data and isinstance(data["known_items"], dict):
                # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç - –æ–±—ä–µ–∫—Ç —Å timestamp
                return set(data["known_items"].keys())
            else:
                return set()
        except Exception:
            return set()
    return set()


def get_item_info(item_id: str) -> Dict:
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–∑–∏—Ü–∏–∏ –∏–∑ state.json"""
    if STATE_PATH.exists():
        try:
            with open(STATE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
                if "known_items" in data and item_id in data["known_items"]:
                    return data["known_items"][item_id]
        except Exception:
            pass
    return {}


def should_monitor_site(site_name: str, interval_hours: int) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω—É–∂–Ω–æ –ª–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å —Å–∞–π—Ç —Å–µ–π—á–∞—Å"""
    from datetime import datetime, timedelta

    # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –≤—Ä–µ–º–µ–Ω–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    last_check_file = STATE_PATH.parent / f"last_check_{site_name}.txt"

    if not last_check_file.exists():
        # –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç, –∑–Ω–∞—á–∏—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–º –≤–ø–µ—Ä–≤—ã–µ
        return True

    try:
        with open(last_check_file, "r") as f:
            last_check_str = f.read().strip()
            last_check = datetime.fromisoformat(last_check_str)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–æ—à–ª–æ –ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Ä–µ–º–µ–Ω–∏
        time_since_last = datetime.now() - last_check
        return time_since_last >= timedelta(hours=interval_hours)

    except Exception:
        # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏, –º–æ–Ω–∏—Ç–æ—Ä–∏–º
        return True


def update_last_check_time(site_name: str):
    """–û–±–Ω–æ–≤–∏—Ç—å –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–∞–π—Ç–∞"""
    from datetime import datetime

    last_check_file = STATE_PATH.parent / f"last_check_{site_name}.txt"
    with open(last_check_file, "w") as f:
        f.write(datetime.now().isoformat())


def load_avito_config() -> Dict:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ê–≤–∏—Ç–æ"""
    config_path = STATE_PATH.parent / "avito_config.json"
    if config_path.exists():
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            pass

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    return {
        "search_queries": ["poets of the fall", "harry potter", "–°–Ω–µ–∂–Ω–∞—è –∫–æ—Ä–æ–ª–µ–≤–∞"],
        "base_url": "https://www.avito.ru/sankt_peterburg_i_lo",
        "category": "hobbi_i_otdyh/muzykalnye_instrumenty",
        "monitor_interval_hours": 6,
        "enabled": True
    }


def scrape_avito_with_playwright() -> List[Dict]:
    """–°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –ê–≤–∏—Ç–æ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –≤–∏–Ω–∏–ª–æ–≤—ã—Ö –ø–ª–∞—Å—Ç–∏–Ω–æ–∫"""
    config = load_avito_config()

    if not config.get("enabled", True):
        print("‚è∞ –ê–≤–∏—Ç–æ: –æ—Ç–∫–ª—é—á–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        return []

    if not should_monitor_site("avito", config.get("monitor_interval_hours", 6)):
        print("‚è∞ –ê–≤–∏—Ç–æ: –ø—Ä–æ–ø—É—Å–∫ (–∏–Ω—Ç–µ—Ä–≤–∞–ª 6 —á–∞—Å–æ–≤)")
        return []

    print("üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ê–≤–∏—Ç–æ...")

    items = []
    search_queries = config.get("search_queries", [])
    base_url = config.get("base_url", "https://www.avito.ru/sankt_peterburg_i_lo")
    category = config.get("category", "kollektsionirovanie")

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            locale="ru-RU",
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            extra_http_headers={
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                "Accept-Language": "ru-RU,ru;q=0.9,en;q=0.8",
                "Accept-Encoding": "gzip, deflate, br",
                "DNT": "1",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
            }
        )
        page = context.new_page()
        page.set_default_timeout(REQUEST_TIMEOUT_SEC * 1000)

        for query in search_queries:
            try:
                # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è –ø–æ–∏—Å–∫–∞
                search_url = f"{base_url}{category}?cd=1&q={query.replace(' ', '+')}"
                print(f"  –ü–æ–∏—Å–∫: {query}")

                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
                page.goto(search_url, wait_until="load", timeout=REQUEST_TIMEOUT_SEC * 1000)
                time.sleep(2)

                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                js = """
                () => {
                  const items = [];
                  const listings = document.querySelectorAll('[data-marker="item"]');

                  for (const listing of listings) {
                    const titleEl = listing.querySelector('[data-marker="item-title"]');
                    const priceEl = listing.querySelector('[data-marker="item-price"]');
                    const linkEl = listing.querySelector('a[data-marker="item-title"]');

                    if (titleEl && linkEl) {
                      const title = titleEl.textContent.trim();
                      const price = priceEl ? priceEl.textContent.trim() : '';
                      const url = linkEl.href;

                      // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –≤–∏–Ω–∏–ª–æ–≤–∞—è –ø–ª–∞—Å—Ç–∏–Ω–∫–∞
                      if (title.toLowerCase().includes('–≤–∏–Ω–∏–ª') ||
                          title.toLowerCase().includes('lp') ||
                          title.toLowerCase().includes('vinyl') ||
                          title.toLowerCase().includes('–ø–ª–∞—Å—Ç–∏–Ω–∫–∞')) {
                        items.push({
                          id: url,
                          url: url,
                          title: title,
                          price: price,
                          query: arguments[0]
                        });
                      }
                    }
                  }

                  return items;
                }
                """

                query_items = page.evaluate(js, query)
                items.extend(query_items)
                print(f"    –ù–∞–π–¥–µ–Ω–æ: {len(query_items)} –ø–æ–∑–∏—Ü–∏–π")

            except Exception as e:
                print(f"    –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ '{query}': {e}")
                continue

        browser.close()

    # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫
    for item in items:
        item["source"] = "avito.ru"

    print(f"üì¶ –ù–∞–π–¥–µ–Ω–æ {len(items)} –ø–æ–∑–∏—Ü–∏–π –Ω–∞ –ê–≤–∏—Ç–æ")
    update_last_check_time("avito")
    return items


def save_state(known_ids: Set[str], new_items: List[Dict] = None) -> None:
    STATE_PATH.parent.mkdir(parents=True, exist_ok=True)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
    existing_data = {}
    if STATE_PATH.exists():
        try:
            with open(STATE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
                if "known_items" in data:
                    existing_data = data["known_items"]
                elif "known_ids" in data:
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –≤ –Ω–æ–≤—ã–π
                    for item_id in data["known_ids"]:
                        existing_data[item_id] = {"added_at": "unknown"}
        except Exception:
            pass

    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å timestamp
    if new_items:
        from datetime import datetime
        current_time = datetime.now().isoformat()
        for item in new_items:
            item_id = item.get("id", "")
            if item_id:
                existing_data[item_id] = {
                    "added_at": current_time,
                    "title": item.get("title", ""),
                    "source": item.get("source", "")
                }

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –Ω–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    with open(STATE_PATH, "w", encoding="utf-8") as f:
        json.dump({"known_items": existing_data}, f, ensure_ascii=False, indent=2)


def send_telegram(text: str) -> None:
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        print("Telegram creds missing; skip notify")
        return
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    try:
        requests.post(
            url,
            json={
                "chat_id": TELEGRAM_CHAT_ID,
                "text": text,
                "parse_mode": "HTML",
                "disable_web_page_preview": True,
            },
            timeout=REQUEST_TIMEOUT_SEC,
        )
    except Exception as e:
        print(f"Failed to send Telegram: {e}")


    def validate_url(url: str) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è URL"""
        if not url or not isinstance(url, str):
            return False
        return url.startswith(('http://', 'https://')) and len(url) < 2048
    
    
def dedupe_keep_order(items: List[Dict]) -> List[Dict]:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π URL –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    seen = set()
    out = []
    duplicates_count = 0
    
    for it in items:
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ–π –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
        url = it.get("url", "")
        if url:
            # –£–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞ –∏ —è–∫–æ—Ä—è
            normalized_url = url.split('?')[0].split('#')[0]
            # –£–±–∏—Ä–∞–µ–º trailing slash
            normalized_url = normalized_url.rstrip('/')
        else:
            normalized_url = it.get("id", "")
        
        if normalized_url and normalized_url not in seen:
            seen.add(normalized_url)
            # –û–±–Ω–æ–≤–ª—è–µ–º ID –Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π URL
            it["id"] = normalized_url
            out.append(it)
        else:
            duplicates_count += 1
            print(f"–î—É–±–ª–∏–∫–∞—Ç –Ω–∞–π–¥–µ–Ω: {normalized_url}")
    
    if duplicates_count > 0:
        print(f"–ù–∞–π–¥–µ–Ω–æ {duplicates_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, —É–¥–∞–ª–µ–Ω–æ")
    
    return out


def advanced_deduplication(items: List[Dict]) -> List[Dict]:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –∏ URL"""
    seen_urls = set()
    seen_content = set()
    out = []
    duplicates_count = 0
    
    for it in items:
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL
        url = it.get("url", "")
        if url:
            normalized_url = url.split('?')[0].split('#')[0].rstrip('/')
        else:
            normalized_url = it.get("id", "")
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        title = it.get("title", "").strip().lower()
        price = it.get("price", "").strip()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ü–µ–Ω—É –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (—É–±–∏—Ä–∞–µ–º –≤–∞–ª—é—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –¥—É–±–ª–∏)
        normalized_price = price.lower()
        # –£–±–∏—Ä–∞–µ–º –≤–∞–ª—é—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        normalized_price = normalized_price.replace('‚Ç¨', '').replace('¬£', '').replace('$', '').replace('—Ä—É–±', '')
        normalized_price = normalized_price.replace('eur', '').replace('gbp', '').replace('usd', '')
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        normalized_price = ' '.join(normalized_price.split())
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —á–∞—Å—Ç–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —á–∏—Å–ª–∞)
        # –ò—â–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —á–∏—Å–ª–∞ –∏ —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏
        numbers = re.findall(r'\d+\.?\d*', normalized_price)
        if len(numbers) > 1 and len(set(numbers)) == 1:  # –í—Å–µ —á–∏—Å–ª–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
            normalized_price = numbers[0]  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —á–∏—Å–ª–æ
        
        content_key = f"{title}|{normalized_price}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ URL –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
        is_duplicate = False
        
        if normalized_url in seen_urls:
            is_duplicate = True
            print(f"–î—É–±–ª–∏–∫–∞—Ç –ø–æ URL: {normalized_url}")
        elif content_key in seen_content and content_key != "|":
            is_duplicate = True
            print(f"–î—É–±–ª–∏–∫–∞—Ç –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É: {title}")
        
        if not is_duplicate:
            seen_urls.add(normalized_url)
            seen_content.add(content_key)
            it["id"] = normalized_url
            out.append(it)
        else:
            duplicates_count += 1
    
    if duplicates_count > 0:
        print(f"–ù–∞–π–¥–µ–Ω–æ {duplicates_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞), —É–¥–∞–ª–µ–Ω–æ")
    
    return out


def extract_items_from_dom(page) -> List[Dict]:
    js = r"""
    () => {
      const anchors = Array.from(document.querySelectorAll('a'))
        .filter(a => a.href && a.href.includes('/catalog/') && a.textContent.trim().length > 0);

      const items = [];
      const seen = new Set();

      for (const a of anchors) {
        // –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL: —É–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞ –∏ —è–∫–æ—Ä—è, —É–±–∏—Ä–∞–µ–º trailing slash
        const url = a.href.split('?')[0].split('#')[0].replace(/\/$/, '');
        if (seen.has(url)) continue;
        seen.add(url);

        let title = a.textContent.trim();
        let el = a;
        for (let i = 0; i < 5 && el; i++) {
          if (el.querySelector) {
            const t = el.querySelector('h1,h2,h3,.title,.product-title,[class*="title"]');
            if (t && t.textContent.trim().length > 3) {
              title = t.textContent.trim();
              break;
            }
          }
          el = el.parentElement;
        }

        el = a;
        let price = '';
        for (let i = 0; i < 5 && el; i++) {
          if (el.querySelector) {
            const p = el.querySelector('.price,[class*="price"],[data-price]');
            if (p && p.textContent) {
              price = p.textContent.trim().replace(/\s+/g, ' ');
              break;
            }
          }
          el = el.parentElement;
        }

        items.push({
          id: url,
          url,
          title,
          price
        });
      }
      return items;
    }
    """
    items = page.evaluate(js)
    return dedupe_keep_order(items)


def safe_scrape(func, url: str) -> List[Dict]:
    try:
        return func(url)
    except Exception as e:
        print(f"Scrape failed for {url}: {e}")
        return []


def validate_message_format(message: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–∂–∏–¥–∞–µ–º–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É:
    ‚Ä¢ –ù–∞–∑–≤–∞–Ω–∏–µ - –¶–µ–Ω–∞ - –°—Å—ã–ª–∫–∞
    """
    if not message or not message.strip():
        return False

    lines = message.strip().split('\n')

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ä–∞–∑–¥–µ–ª–æ–≤
        if line.startswith('üéµ') or line.startswith('üè†') or line.startswith('üì¶'):
            continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Å—Ç—Ä–æ–∫–∏ —Å —Ç–æ–≤–∞—Ä–æ–º
        if line.startswith('- '):
            # –£–±–∏—Ä–∞–µ–º "- " –≤ –Ω–∞—á–∞–ª–µ
            content = line[2:].strip()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å—Å—ã–ª–∫–∏
            if '<a href=' not in content or '</a>' not in content:
                return False

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ —Ü–µ–Ω–∞
            # –§–æ—Ä–º–∞—Ç: <a href="url">–Ω–∞–∑–≤–∞–Ω–∏–µ</a> ‚Äî —Ü–µ–Ω–∞
            if ' ‚Äî ' not in content:
                return False

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–µ –ø—É—Å—Ç–æ–µ
            title_start = content.find('>') + 1
            title_end = content.find('</a>')
            if title_start <= 1 or title_end <= title_start:
                return False

            title = content[title_start:title_end].strip()
            if not title or title == '(–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)':
                return False

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–Ω—É –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
            price_part = content[content.find(' ‚Äî ') + 3:].strip()
            if price_part:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞–ª—é—Ç–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
                currency_symbols = ['¬£', '‚Ç¨', '$', '—Ä—É–±']
                for symbol in currency_symbols:
                    if price_part.count(symbol) > 1:
                        return False

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ EUR/GBP
                if price_part.count('EUR') > 1 or price_part.count('GBP') > 1:
                    return False

    return True


def chunk_messages(text: str, limit: int = 4096) -> List[str]:
    if len(text) <= limit:
        return [text]
    chunks: List[str] = []
    current = []
    current_len = 0
    for line in text.split("\n"):
        add_len = len(line) + 1
        if current_len + add_len > limit:
            chunks.append("\n".join(current))
            current = [line]
            current_len = len(line) + 1
        else:
            current.append(line)
            current_len += add_len
    if current:
        chunks.append("\n".join(current))
    return chunks


def extract_vinyltap_from_dom(page) -> List[Dict]:
    js = r"""
    () => {
      const anchors = Array.from(document.querySelectorAll('a'))
        .filter(a => a.href && a.href.includes('/products/') && a.textContent.trim().length > 0);

      const items = [];
      const seen = new Set();

      for (const a of anchors) {
        // –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL: —É–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞ –∏ —è–∫–æ—Ä—è, —É–±–∏—Ä–∞–µ–º trailing slash
        const url = a.href.split('?')[0].split('#')[0].replace(/\/$/, '');
        if (seen.has(url)) continue;
        seen.add(url);

        let title = a.textContent.trim();
        let el = a;
        for (let i = 0; i < 5 && el; i++) {
          if (el.querySelector) {
            const t = el.querySelector('h1,h2,h3,.title,.product-title,[class*="title"],.card__heading');
            if (t && t.textContent.trim().length > 3) {
              title = t.textContent.trim();
              break;
            }
          }
          el = el.parentElement;
        }

        // –§–ò–õ–¨–¢–†–ê–¶–ò–Ø: —Ç–æ–ª—å–∫–æ –≤–∏–Ω–∏–ª–æ–≤—ã–µ –ø–ª–∞—Å—Ç–∏–Ω–∫–∏ (LP, Vinyl, 7 Inch, 12 Inch)
        const titleLower = title.toLowerCase();
        const isVinyl = titleLower.includes('lp') ||
                       titleLower.includes('vinyl') ||
                       titleLower.includes('7 inch') ||
                       titleLower.includes('12 inch') ||
                       titleLower.includes('7"') ||
                       titleLower.includes('12"') ||
                       (titleLower.includes('inch') && !titleLower.includes('cd') && !titleLower.includes('dvd'));

        // –ò—Å–∫–ª—é—á–∞–µ–º CD, DVD, –∫–∞—Å—Å–µ—Ç—ã
        const isNotVinyl = titleLower.includes('cd') ||
                          titleLower.includes('dvd') ||
                          titleLower.includes('cassette') ||
                          titleLower.includes('tape');

        if (!isVinyl || isNotVinyl) {
          continue; // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–≤–∏–Ω–∏–ª–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã
        }

        el = a;
        let price = '';
        for (let i = 0; i < 5 && el; i++) {
          if (el.querySelector) {
            const p = el.querySelector('.price,.money,[class*="price"]');
            if (p && p.textContent) {
              price = p.textContent.trim().replace(/\s+/g, ' ');
              // –û—á–∏—â–∞–µ–º —Ü–µ–Ω—É –æ—Ç –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
              price = price.replace(/Regular price\s*/gi, '')
                          .replace(/Sale price\s*/gi, '')
                          .replace(/Unit price\s*\/\s*per\s*/gi, '')
                          .replace(/\s+/g, ' ')
                          .trim();

              // –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–Ω—ã (–µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —á–∞—Å—Ç–∏)
              // –ò—â–µ–º —Å–∏–º–≤–æ–ª—ã –≤–∞–ª—é—Ç: ¬£, ‚Ç¨, $, —Ä—É–±
              const currencySymbols = ['¬£', '‚Ç¨', '$', '—Ä—É–±'];
              let foundCurrency = null;
              for (const symbol of currencySymbols) {
                if (price.includes(symbol)) {
                  foundCurrency = symbol;
                  break;
                }
              }

              if (foundCurrency) {
                // –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Å–∏–º–≤–æ–ª—É –≤–∞–ª—é—Ç—ã
                const priceParts = price.split(foundCurrency);
                if (priceParts.length > 2) {
                  // –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —Ü–µ–Ω—É (—á–∞—Å—Ç—å –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ –≤–∞–ª—é—Ç—ã + —Å–∏–º–≤–æ–ª + —á–∞—Å—Ç—å –ø–æ—Å–ª–µ)
                  price = priceParts[0] + foundCurrency + priceParts[1];
                }

                // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ EUR/GBP
                if (price.includes('EUR') && price.includes('‚Ç¨')) {
                  // –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ EUR –ø–æ—Å–ª–µ ‚Ç¨
                  price = price.replace(/‚Ç¨([^‚Ç¨]*?)EUR\s*‚Ç¨\1EUR/g, '‚Ç¨$1EUR');
                  // –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –µ—Å—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å
                  if (price.includes('‚Ç¨') && price.split('‚Ç¨').length > 2) {
                    const parts = price.split('‚Ç¨');
                    price = parts[0] + '‚Ç¨' + parts[1];
                  }
                }
                
                // –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è GBP
                if (price.includes('GBP') && price.includes('¬£')) {
                  price = price.replace(/¬£([^¬£]*?)GBP\s*¬£\1GBP/g, '¬£$1GBP');
                  if (price.includes('¬£') && price.split('¬£').length > 2) {
                    const parts = price.split('¬£');
                    price = parts[0] + '¬£' + parts[1];
                  }
                }
              }
              break;
            }
          }
          el = el.parentElement;
        }

        items.push({ id: url, url, title, price });
      }
      return items;
    }
    """
    items = page.evaluate(js)
    return dedupe_keep_order(items)


def scrape_with_playwright() -> List[Dict]:
    all_items = []
    urls = [CATALOG_URL, KOROBKA_SALE_URL]

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            locale="ru-RU",
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            extra_http_headers={
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                "Accept-Language": "ru-RU,ru;q=0.9,en;q=0.8",
                "Accept-Encoding": "gzip, deflate, br",
                "DNT": "1",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
            }
        )
        page = context.new_page()
        page.set_default_timeout(REQUEST_TIMEOUT_SEC * 1000)

        for url in urls:
            try:
                section_name = "–∫–∞—Ç–∞–ª–æ–≥" if "Sale" not in url else "—Å–∫–∏–¥–∫–∏"
                print(f"  –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ {section_name}: {url}")

                # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
                for attempt in range(3):
                    try:
                        page.goto(url, wait_until="load", timeout=REQUEST_TIMEOUT_SEC * 1000)
                        break
                    except Exception as e:
                        print(f"    –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–µ—É–¥–∞—á–Ω–∞: {e}")
                        if attempt < 2:
                            time.sleep(2)
                        else:
                            print(f"    –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {section_name} –ø–æ—Å–ª–µ 3 –ø–æ–ø—ã—Ç–æ–∫")
                            continue
            except Exception as e:
                print(f"    –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {section_name}: {e}")
                continue

        time.sleep(1.2)

        clicks = 0
        while clicks < LOAD_MORE_MAX_CLICKS:
            btn = page.locator("text=Load more").or_(page.locator("text=–ó–∞–≥—Ä—É–∑–∏—Ç—å –µ—â—ë")).or_(page.locator("text=–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë"))
            if btn.count() == 0:
                break
            try:
                btn.first.scroll_into_view_if_needed()
                btn.first.click()
                clicks += 1
                page.wait_for_timeout(LOAD_MORE_WAIT_MS)
            except Exception:
                break

            items = extract_items_from_dom(page)
            print(f"    –ù–∞–π–¥–µ–Ω–æ: {len(items)} –ø–æ–∑–∏—Ü–∏–π")
            all_items.extend(items)

        browser.close()

        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫
        for item in all_items:
            item["source"] = "korobkavinyla.ru"

        return all_items


def scrape_plastinka_with_playwright() -> List[Dict]:
    """–°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å plastinka.com –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –≤–∏–Ω–∏–ª–æ–≤—ã—Ö –ø–ª–∞—Å—Ç–∏–Ω–æ–∫"""
    if not should_monitor_site("plastinka", PLASTINKA_MONITOR_INTERVAL_HOURS):
        print("‚è∞ plastinka.com: –ø—Ä–æ–ø—É—Å–∫ (–∏–Ω—Ç–µ—Ä–≤–∞–ª 6 —á–∞—Å–æ–≤)")
        return []

    print("üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ plastinka.com...")
    all_items = []

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            locale="ru-RU",
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            extra_http_headers={
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                "Accept-Language": "ru-RU,ru;q=0.9,en;q=0.8",
                "Accept-Encoding": "gzip, deflate, br",
                "DNT": "1",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
            }
        )
        page = context.new_page()
        page.set_default_timeout(REQUEST_TIMEOUT_SEC * 1000)

        try:
            print(f"  –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: {PLASTINKA_URL}")

            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
            for attempt in range(3):
                try:
                    page.goto(PLASTINKA_URL, wait_until="load", timeout=REQUEST_TIMEOUT_SEC * 1000)
                    break
                except Exception as e:
                    print(f"    –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–µ—É–¥–∞—á–Ω–∞: {e}")
                    if attempt < 2:
                        time.sleep(2)
                    else:
                        print("    –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å plastinka.com –ø–æ—Å–ª–µ 3 –ø–æ–ø—ã—Ç–æ–∫")
                        continue

            time.sleep(1.2)

            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–∂–∞—Ç—å –∫–Ω–æ–ø–∫—É –ø–æ–¥–≥—Ä—É–∑–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
            try:
                for _ in range(3):
                    btn = page.locator("text=Load more").or_(page.locator("text=–ó–∞–≥—Ä—É–∑–∏—Ç—å –µ—â—ë")).or_(page.locator("text=–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë"))
                    if btn.count() == 0:
                        break
                    btn.first.scroll_into_view_if_needed()
                    btn.first.click()
                    page.wait_for_timeout(LOAD_MORE_WAIT_MS)
            except Exception as e:
                print(f"    –û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞–∂–∞—Ç–∏–∏ –∫–Ω–æ–ø–∫–∏ 'Load more': {e}")

            try:
                items = extract_plastinka_from_dom(page)
                print(f"    –ù–∞–π–¥–µ–Ω–æ: {len(items)} –ø–æ–∑–∏—Ü–∏–π")
                all_items.extend(items)
            except Exception as e:
                print(f"    –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")

        except Exception as e:
            print(f"    –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ plastinka.com: {e}")

        browser.close()

        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫
        for item in all_items:
            item["source"] = "plastinka.com"

        return all_items


def extract_plastinka_from_dom(page) -> List[Dict]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–∞—Ö —Å plastinka.com"""
    js = r"""
    () => {
      const anchors = Array.from(document.querySelectorAll('a'))
        .filter(a => a.href && (a.href.includes('/product/') || a.href.includes('/lp/')) && a.textContent.trim().length > 0);

      const items = [];
      const seen = new Set();

      for (const a of anchors) {
        // –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL: —É–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞ –∏ —è–∫–æ—Ä—è, —É–±–∏—Ä–∞–µ–º trailing slash
        const url = a.href.split('?')[0].split('#')[0].replace(/\/$/, '');
        if (seen.has(url)) continue;
        seen.add(url);

        let title = a.textContent.trim();
        let el = a;
        
        // –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –≤ —Å–∞–º–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ –∏ –µ–≥–æ –±–ª–∏–∂–∞–π—à–∏—Ö —Ä–æ–¥–∏—Ç–µ–ª—è—Ö
        let currentEl = a;
        for (let i = 0; i < 3 && currentEl; i++) {
          if (currentEl.querySelector) {
            // –ò—â–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏–π –≤ —Ç–µ–∫—É—â–µ–º —ç–ª–µ–º–µ–Ω—Ç–µ
            const titleSelectors = [
              '.t-store__prod-snippet__title',
              '.t-store__prod-snippet__title a',
              '.t-store__prod-snippet__title span',
              '.t-store__prod-snippet__title div',
              'h1,h2,h3,h4,h5,h6',
              '.title,.product-title,[class*="title"]',
              '.t-store__prod-snippet__title-wrapper',
              '.t-store__prod-snippet__title-wrapper a',
              '.t-store__prod-snippet__title-wrapper span'
            ];
            
            for (const selector of titleSelectors) {
              const t = currentEl.querySelector(selector);
              if (t && t.textContent && t.textContent.trim().length > 3) {
                const foundTitle = t.textContent.trim();
                // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ –≥–æ–¥ –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç
                if (foundTitle.length > title.length && !foundTitle.match(/^\\d{2,4}$/)) {
                  title = foundTitle;
                  break;
                }
              }
            }
            
            // –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã title –∏ alt
            if (currentEl.title && currentEl.title.trim().length > title.length) {
              title = currentEl.title.trim();
            }
            if (currentEl.alt && currentEl.alt.trim().length > title.length) {
              title = currentEl.alt.trim();
            }
          }
          currentEl = currentEl.parentElement;
        }
        
        // –ï—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –≤—Å–µ –µ—â–µ –∫–æ—Ä–æ—Ç–∫–æ–µ, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ URL
        if (title.length < 10 && a.href) {
          const urlParts = a.href.split('/');
          const lastPart = urlParts[urlParts.length - 1];
          if (lastPart && lastPart.includes('-')) {
            const urlTitle = lastPart.replace(/-/g, ' ').replace(/\\d+/g, '').trim();
            if (urlTitle.length > title.length) {
              title = urlTitle;
            }
          }
        }
        
        // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –æ–±—â–µ–µ, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        if (title.length < 15 || title.includes('Boccherini/Bach')) {
          // –ò—â–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤ —Å–æ—Å–µ–¥–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
          const parent = a.parentElement;
          if (parent) {
            const siblings = Array.from(parent.children);
            for (const sibling of siblings) {
              if (sibling !== a && sibling.textContent) {
                const siblingText = sibling.textContent.trim();
                if (siblingText.length > title.length && 
                    !siblingText.toLowerCase().includes('—Ä—É–±') &&
                    !siblingText.toLowerCase().includes('–∫—É–ø–∏—Ç—å') &&
                    !siblingText.toLowerCase().includes('–≤ –∫–æ—Ä–∑–∏–Ω—É')) {
                  title = siblingText;
                  break;
                }
              }
            }
          }
        }

        let price = '';
        let originalPrice = '';
        let discountPrice = '';
        el = a;
        for (let i = 0; i < 5 && el; i++) {
          if (el.querySelector) {
            // –ò—â–µ–º —Ü–µ–Ω—É —Å–æ —Å–∫–∏–¥–∫–æ–π
            const discountEl = el.querySelector('.t-store__prod-snippet__price, .price, .money, [class*="price"]');
            if (discountEl && discountEl.textContent) {
              const priceText = discountEl.textContent.trim();
              
              // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–≤–µ —Ü–µ–Ω—ã (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –∏ —Å–æ —Å–∫–∏–¥–∫–æ–π)
              const priceMatch = priceText.match(/(\d+[\s,]*\d*)\s*—Ä—É–±\.?\s*(\d+[\s,]*\d*)\s*—Ä—É–±\.?/);
              if (priceMatch) {
                originalPrice = priceMatch[1].replace(/\s/g, '') + ' —Ä—É–±.';
                discountPrice = priceMatch[2].replace(/\s/g, '') + ' —Ä—É–±.';
                price = `${originalPrice} ‚Üí ${discountPrice}`;
              } else {
                price = priceText.replace(/\s+/g, ' ');
              }
              break;
            }
          }
          el = el.parentElement;
        }

        // –§–∏–ª—å—Ç—Ä—É–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –º–µ–Ω—é –∏ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
        if (title && title.length > 3 && 
            !title.toLowerCase().includes('–º–µ–Ω—é') && 
            !title.toLowerCase().includes('–∫–∞—Ç–∞–ª–æ–≥') &&
            !title.toLowerCase().includes('–≥–ª–∞–≤–Ω–∞—è') &&
            !title.toLowerCase().includes('–∫–æ–Ω—Ç–∞–∫—Ç—ã') &&
            !title.toLowerCase().includes('style/') &&
            !title.toLowerCase().includes('–∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –≤—ã–±–æ—Ä') &&
            !title.toLowerCase().includes('–Ω–æ–≤—ã–µ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è') &&
            !title.toLowerCase().includes('–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–∏–Ω–∏–ª') &&
            !title.toLowerCase().includes('–ø–æ–¥–∞—Ä–æ—á–Ω—ã–µ –∏–∑–¥–∞–Ω–∏—è') &&
            !title.toLowerCase().includes('record store day') &&
            !url.includes('/style/') &&
            url.includes('/item/')) {  // –¢–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä—ã
          items.push({
            id: url,
            url: url,
            title: title,
            price: price
          });
        }
      }

      return items;
    }
    """
    return page.evaluate(js)


def scrape_vinyltap_with_playwright() -> List[Dict]:
    all_items = []

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            locale="en-GB",
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            extra_http_headers={
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                "Accept-Language": "en-GB,en;q=0.9,en-US;q=0.8",
                "Accept-Encoding": "gzip, deflate, br",
                "DNT": "1",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
            }
        )
        page = context.new_page()
        page.set_default_timeout(REQUEST_TIMEOUT_SEC * 1000)

        for url in VINYLTAP_URLS:
            try:
                print(f"  –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: {url}")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
                for attempt in range(3):
                    try:
                        page.goto(url, wait_until="domcontentloaded", timeout=REQUEST_TIMEOUT_SEC * 1000)
                        break
                    except Exception as e:
                        print(f"    –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–µ—É–¥–∞—á–Ω–∞: {e}")
                        if attempt < 2:
                            time.sleep(2)
                        else:
                            print(f"    –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {url} –ø–æ—Å–ª–µ 3 –ø–æ–ø—ã—Ç–æ–∫")
                            continue
                
                time.sleep(1.2)

                # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–∂–∞—Ç—å –∫–Ω–æ–ø–∫—É –ø–æ–¥–≥—Ä—É–∑–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
                try:
                    for _ in range(3):
                        btn = page.locator("text=Load more").or_(page.locator("text=Show more")).or_(page.locator("text=More"))
                        if btn.count() == 0:
                            break
                        btn.first.scroll_into_view_if_needed()
                        btn.first.click()
                        page.wait_for_timeout(LOAD_MORE_WAIT_MS)
                except Exception as e:
                    print(f"    –û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞–∂–∞—Ç–∏–∏ –∫–Ω–æ–ø–∫–∏ 'Load more': {e}")

                try:
                    items = extract_vinyltap_from_dom(page)
                    print(f"    –ù–∞–π–¥–µ–Ω–æ: {len(items)} –ø–æ–∑–∏—Ü–∏–π")
                    all_items.extend(items)
                except Exception as e:
                    print(f"    –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")

            except Exception as e:
                print(f"    –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ {url}: {e}")
                continue

            browser.close()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫
        for item in all_items:
            item["source"] = "vinyltap.co.uk"

        return all_items


def main():
    print("üéµ –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∞ –≤–∏–Ω–∏–ª–æ–≤—ã—Ö –ø–ª–∞—Å—Ç–∏–Ω–æ–∫...")
    known = load_state()
    print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(known)} –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è")

    items: List[Dict] = []
    if USE_PLAYWRIGHT:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å korobkavinyla.ru
        if should_monitor_site("korobkavinyla", KOROBKA_MONITOR_INTERVAL_HOURS):
            print("üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ korobkavinyla.ru...")
            korobka_items = scrape_with_playwright()
            print(f"üì¶ –ù–∞–π–¥–µ–Ω–æ {len(korobka_items)} –ø–æ–∑–∏—Ü–∏–π –Ω–∞ korobkavinyla.ru")
            items.extend(korobka_items)
            update_last_check_time("korobkavinyla")
        else:
            print("‚è∞ korobkavinyla.ru: –ø—Ä–æ–ø—É—Å–∫ (–∏–Ω—Ç–µ—Ä–≤–∞–ª 24 —á–∞—Å–∞)")
            korobka_items = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å vinyltap.co.uk
        if should_monitor_site("vinyltap", VINYLTAP_MONITOR_INTERVAL_HOURS):
            print("üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ vinyltap.co.uk...")
            vinyltap_items = scrape_vinyltap_with_playwright()
            print(f"üì¶ –ù–∞–π–¥–µ–Ω–æ {len(vinyltap_items)} –ø–æ–∑–∏—Ü–∏–π –Ω–∞ vinyltap.co.uk")
            items.extend(vinyltap_items)
            update_last_check_time("vinyltap")
        else:
            print("‚è∞ vinyltap.co.uk: –ø—Ä–æ–ø—É—Å–∫ (–∏–Ω—Ç–µ—Ä–≤–∞–ª 3 —á–∞—Å–∞)")
            vinyltap_items = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –ê–≤–∏—Ç–æ
        avito_items = scrape_avito_with_playwright()
        items.extend(avito_items)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å plastinka.com
        plastinka_items = scrape_plastinka_with_playwright()
        items.extend(plastinka_items)
    else:
        items = []

    print(f"üîÑ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è {len(items)} –ø–æ–∑–∏—Ü–∏–π...")
    items = advanced_deduplication(items)
    print(f"‚úÖ –ü–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {len(items)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π")

    current_ids = {it["id"] for it in items}
    new_ids = [it for it in items if it["id"] not in known]
    
    print(f"üÜï –ù–∞–π–¥–µ–Ω–æ {len(new_ids)} –Ω–æ–≤—ã—Ö –ø–æ–∑–∏—Ü–∏–π –∏–∑ {len(items)} –æ–±—â–∏—Ö")

    if new_ids:
        lines = ["–ù–æ–≤—ã–µ –ø–æ–∑–∏—Ü–∏–∏:"]
        kor_items = [it for it in new_ids if it.get("source") == "korobkavinyla.ru"]
        tap_items = [it for it in new_ids if it.get("source") == "vinyltap.co.uk"]
        avito_items = [it for it in new_ids if it.get("source") == "avito.ru"]

        if kor_items:
            lines.append("üéµ korobkavinyla.ru:")
            for it in kor_items:
                title = it.get('title', '(–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)')
                price = f" ‚Äî {it['price']}" if it.get('price') else ''
                url = it['url']
                safe_title = escape(title)
                lines.append(f"- <a href=\"{url}\">{safe_title}</a>{price}")

        if tap_items:
            lines.append("üéµ vinyltap.co.uk:")
            for it in tap_items:
                title = it.get('title', '(–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)')
                price = it.get('price', '')

                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –≤–∞–ª—é—Ç—É –¥–ª—è vinyltap.co.uk (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å ¬£, –∞ –Ω–µ ‚Ç¨)
                if price and '‚Ç¨' in price:
                    # –ó–∞–º–µ–Ω—è–µ–º ‚Ç¨ –Ω–∞ ¬£ –¥–ª—è vinyltap.co.uk
                    price = price.replace('‚Ç¨', '¬£')
                    # –£–±–∏—Ä–∞–µ–º EUR –∏ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ GBP
                    price = price.replace('EUR', 'GBP')

                price_str = f" ‚Äî {price}" if price else ''
                url = it['url']
                safe_title = escape(title)
                lines.append(f"- <a href=\"{url}\">{safe_title}</a>{price_str}")

        if avito_items:
            lines.append("üè† –ê–≤–∏—Ç–æ:")
            for it in avito_items:
                title = it.get('title', '(–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)')
                price = f" ‚Äî {it['price']}" if it.get('price') else ''
                url = it['url']
                query = it.get('query', '')
                query_info = f" (–ø–æ–∏—Å–∫: {query})" if query else ''
                safe_title = escape(title)
                lines.append(f"- <a href=\"{url}\">{safe_title}</a>{price}{query_info}")

        if plastinka_items:
            lines.append("üíø plastinka.com:")
            for it in plastinka_items:
                title = it.get('title', '(–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)')
                price = it.get('price', '')
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ü–µ–Ω—É –¥–ª—è —Å–∫–∏–¥–æ–∫
                if price and '‚Üí' in price:
                    # –¶–µ–Ω–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å —ç–º–æ–¥–∑–∏
                    price_str = f" ‚Äî üí∞ {price}"
                elif price:
                    price_str = f" ‚Äî {price}"
                else:
                    price_str = ''
                
                url = it['url']
                safe_title = escape(title)
                lines.append(f"- <a href=\"{url}\">{safe_title}</a>{price_str}")

        message = "\n".join(lines)
        print(f"üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ {len(new_ids)} –Ω–æ–≤—ã—Ö –ø–æ–∑–∏—Ü–∏–π –≤ Telegram...")
        for chunk in chunk_messages(message):
            send_telegram(chunk)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ç–æ–ª—å–∫–æ —Å –Ω–æ–≤—ã–º–∏ ID
        updated_known = known.union(current_ids)
        save_state(updated_known, new_ids)
        print(f"üíæ –°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {len(updated_known)} –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π")
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö: {len(new_ids)}")
    else:
        print("‚ÑπÔ∏è –ù–æ–≤—ã—Ö –ø–æ–∑–∏—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")


if __name__ == "__main__":
    main()
